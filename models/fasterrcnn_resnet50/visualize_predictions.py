# -*- coding: utf-8 -*-
"""visualize_predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mMbCcBKGVojnSwhwfB5EopVHzCU88QKJ
"""

import os
import cv2
import torch
from torchvision.transforms import ToTensor
from matplotlib import pyplot as plt
from PIL import Image
from voc_dataset import VOCDataset

def visualize(model, dataset_root, num_images=5, image_set="val", confidence_threshold=0.5):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model.eval()
    model.to(device)

    # Load trained weights if available
    weight_path = "checkpoints/baseline_sonar_fasterrcnn.pth"
    if os.path.exists(weight_path):
        model.load_state_dict(torch.load(weight_path, map_location=device))
        print("Loaded model weights from:", weight_path)
    else:
        print("No weights found. Using default model weights.")

    # Load dataset
    dataset = VOCDataset(dataset_root, image_set=image_set, transforms=ToTensor())

    for i in range(num_images):
        img, _ = dataset[i]
        img_tensor = img.unsqueeze(0).to(device)
        with torch.no_grad():
            output = model(img_tensor)[0]

        img_np = img.mul(255).byte().permute(1, 2, 0).cpu().numpy()
        img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR).copy()

        for box, score in zip(output["boxes"], output["scores"]):
            if score < confidence_threshold:
                continue
            x1, y1, x2, y2 = box.int().tolist()
            cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img_np, f"{score:.2f}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

        plt.imshow(cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB))
        plt.axis("off")
        plt.show()

# Call visualization function
visualize(model, "/content/drive/MyDrive/sonar-object-detection/data/line2voc", num_images=5)