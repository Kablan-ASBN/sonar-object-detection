# -*- coding: utf-8 -*-
"""voc_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1618vAppv3qJE5FCk32Os1yWXQR7sXH4y
"""

# voc_dataset.py

import os
import xml.etree.ElementTree as ET
import torch
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as T

class VOCDataset(Dataset):
    def __init__(self, root, image_set="train", transforms=None):
        """
        Custom dataset loader for Pascal VOC-style sonar annotations.
        This class loads images and their XML annotations for object detection.

        Args:
            root (str): Path to the VOC-format dataset root directory.
            image_set (str): One of 'train', 'val', or 'test'.
            transforms (callable, optional): Optional image transformations (e.g., ToTensor).
        """
        self.root = root
        self.transforms = transforms

        self.image_dir = os.path.join(root, "JPEGImages")
        self.ann_dir = os.path.join(root, "Annotations")
        split_path = os.path.join(root, "ImageSets", "Main", f"{image_set}.txt")

        if not os.path.isfile(split_path):
            raise FileNotFoundError(f"Missing split file: {split_path}")

        with open(split_path) as f:
            self.image_ids = [x.strip() for x in f.readlines()]

        # Class mapping must match your training logic
        # 0 = background (implicit), 1 = object, 2 = shadow
        self.class_map = {"object": 1, "shadow": 2}

    def __len__(self):
        return len(self.image_ids)

    def __getitem__(self, idx):
        """
        Loads an image and its corresponding VOC annotation.

        Returns:
            img (Tensor): The transformed image tensor.
            target (dict): A dictionary containing 'boxes' and 'labels' tensors.
        """
        img_id = self.image_ids[idx]
        img_path = os.path.join(self.image_dir, f"{img_id}.jpg")
        ann_path = os.path.join(self.ann_dir, f"{img_id}.xml")

        img = Image.open(img_path).convert("RGB")
        target = self.parse_voc_xml(ann_path)

        if self.transforms:
            img = self.transforms(img)

        return img, target

    def parse_voc_xml(self, xml_path):
        """
        Parses a Pascal VOC annotation file to extract bounding boxes and labels.

        Args:
            xml_path (str): Path to a VOC-style XML file.

        Returns:
            dict: A dictionary with keys 'boxes' and 'labels', both as tensors.
        """
        tree = ET.parse(xml_path)
        root = tree.getroot()

        boxes = []
        labels = []

        for obj in root.findall("object"):
            class_name = obj.find("name").text.strip().lower()
            label = self.class_map.get(class_name)

            if label is None:
                continue  # skip unknown or unexpected classes

            bbox = obj.find("bndbox")
            xmin = int(float(bbox.find("xmin").text))
            ymin = int(float(bbox.find("ymin").text))
            xmax = int(float(bbox.find("xmax").text))
            ymax = int(float(bbox.find("ymax").text))

            if xmax - xmin < 1 or ymax - ymin < 1:
                continue  # skip invalid or degenerate boxes

            boxes.append([xmin, ymin, xmax, ymax])
            labels.append(label)

        # Handle empty annotation case with dummy values
        if not boxes:
            boxes = [[0, 0, 1, 1]]
            labels = [0]

        return {
            "boxes": torch.tensor(boxes, dtype=torch.float32),
            "labels": torch.tensor(labels, dtype=torch.int64)
        }