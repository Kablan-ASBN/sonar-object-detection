{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMEcJDzH2isquHgYbGG+g/m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# =============================================================\n","# STEP 1: Mount Google Drive\n","# =============================================================\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# =============================================================\n","# STEP 2: Import libraries and define paths\n","# =============================================================\n","import os, random, shutil\n","from pathlib import Path\n","from PIL import Image\n","from collections import defaultdict\n","from xml.etree.ElementTree import Element, SubElement, tostring\n","from xml.dom.minidom import parseString\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from tqdm import tqdm\n","from threading import Lock\n","\n","# Define root paths\n","PROJECT_ROOT = Path(\"/content/drive/MyDrive/sonar-object-detection\")\n","SOURCE_LABELS = PROJECT_ROOT / \"data\" / \"line2yolo\" / \"labels\"\n","SOURCE_IMAGES = PROJECT_ROOT / \"data\" / \"line2yolo\" / \"images\"\n","TARGET_ROOT = PROJECT_ROOT / \"data\" / \"line2voc\"\n","\n","# Define Pascal VOC structure\n","ANNOTATIONS_DIR = TARGET_ROOT / \"Annotations\"\n","IMAGES_DIR = TARGET_ROOT / \"JPEGImages\"\n","IMAGESETS_MAIN = TARGET_ROOT / \"ImageSets\" / \"Main\"\n","\n","# Create folders\n","ANNOTATIONS_DIR.mkdir(parents=True, exist_ok=True)\n","IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n","IMAGESETS_MAIN.mkdir(parents=True, exist_ok=True)\n","\n","# Define class mapping\n","CLASS_NAMES = [\"object\", \"shadow\"]\n","IMG_EXTENSIONS = [\".jpg\", \".jpeg\", \".png\"]\n","\n","# =============================================================\n","# STEP 3: Define conversion helpers\n","# =============================================================\n","\n","def convert_box(image_size, yolo_box):\n","    x, y, w, h = yolo_box\n","    img_w, img_h = image_size\n","    x_min = int((x - w / 2) * img_w)\n","    y_min = int((y - h / 2) * img_h)\n","    x_max = int((x + w / 2) * img_w)\n","    y_max = int((y + h / 2) * img_h)\n","    return x_min, y_min, x_max, y_max\n","\n","def create_voc_xml(image_path, objects, image_size):\n","    annotation = Element('annotation')\n","    SubElement(annotation, 'folder').text = image_path.parent.name\n","    SubElement(annotation, 'filename').text = image_path.name\n","    size = SubElement(annotation, 'size')\n","    SubElement(size, 'width').text = str(image_size[0])\n","    SubElement(size, 'height').text = str(image_size[1])\n","    SubElement(size, 'depth').text = \"3\"\n","\n","    for obj in objects:\n","        obj_tag = SubElement(annotation, 'object')\n","        SubElement(obj_tag, 'name').text = obj['class']\n","        SubElement(obj_tag, 'pose').text = \"Unspecified\"\n","        SubElement(obj_tag, 'truncated').text = \"0\"\n","        SubElement(obj_tag, 'difficult').text = \"0\"\n","        bbox = SubElement(obj_tag, 'bndbox')\n","        SubElement(bbox, 'xmin').text = str(obj['xmin'])\n","        SubElement(bbox, 'ymin').text = str(obj['ymin'])\n","        SubElement(bbox, 'xmax').text = str(obj['xmax'])\n","        SubElement(bbox, 'ymax').text = str(obj['ymax'])\n","\n","    return parseString(tostring(annotation)).toprettyxml(indent=\"  \")\n","\n","# =============================================================\n","# STEP 4: Threaded conversion for speed\n","# =============================================================\n","converted = []\n","skipped_no_image = 0\n","skipped_empty = 0\n","skipped_invalid_class = 0\n","lock = Lock()\n","\n","def process_annotation(txt_file):\n","    global skipped_no_image, skipped_empty, skipped_invalid_class\n","\n","    base = txt_file.name.replace(\".txt\", \"\")\n","    img_file = next((f for f in SOURCE_IMAGES.glob(\"*\")\n","                     if f.name.startswith(base) and f.suffix.lower() in IMG_EXTENSIONS), None)\n","\n","    if img_file is None:\n","        with lock:\n","            skipped_no_image += 1\n","        return None\n","\n","    with open(txt_file, \"r\") as f:\n","        lines = f.read().strip().splitlines()\n","    if not lines:\n","        with lock:\n","            skipped_empty += 1\n","        return None\n","\n","    with Image.open(img_file) as img:\n","        w, h = img.size\n","\n","    objects = []\n","    for line in lines:\n","        parts = line.strip().split()\n","        if len(parts) != 5:\n","            continue\n","        class_id = int(parts[0])\n","        if class_id >= len(CLASS_NAMES):\n","            with lock:\n","                skipped_invalid_class += 1\n","            continue\n","        yolo_box = list(map(float, parts[1:]))\n","        xmin, ymin, xmax, ymax = convert_box((w, h), yolo_box)\n","        objects.append({\n","            \"class\": CLASS_NAMES[class_id],\n","            \"xmin\": xmin,\n","            \"ymin\": ymin,\n","            \"xmax\": xmax,\n","            \"ymax\": ymax,\n","        })\n","\n","    if not objects:\n","        with lock:\n","            skipped_empty += 1\n","        return None\n","\n","    xml_path = ANNOTATIONS_DIR / f\"{img_file.stem}.xml\"\n","    with open(xml_path, \"w\") as f:\n","        f.write(create_voc_xml(img_file, objects, (w, h)))\n","\n","    jpg_path = IMAGES_DIR / f\"{img_file.stem}.jpg\"\n","    with Image.open(img_file) as im:\n","        im.convert(\"RGB\").save(jpg_path, \"JPEG\")\n","\n","    return img_file.stem\n","\n","# =============================================================\n","# STEP 5: Run threaded conversion with progress bar\n","# =============================================================\n","txt_files = list(SOURCE_LABELS.glob(\"*.txt\"))\n","converted = []\n","\n","with ThreadPoolExecutor(max_workers=8) as executor:\n","    futures = {executor.submit(process_annotation, txt_file): txt_file for txt_file in txt_files}\n","    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Converting YOLO to VOC\"):\n","        result = future.result()\n","        if result:\n","            converted.append(result)\n","\n","# =============================================================\n","# STEP 6: Create stratified train/val/test splits\n","# =============================================================\n","grouped = defaultdict(list)\n","\n","for txt_file in SOURCE_LABELS.glob(\"*.txt\"):\n","    base = txt_file.name.replace(\".txt\", \"\")\n","    if base not in converted:\n","        continue\n","\n","    with open(txt_file, \"r\") as f:\n","        lines = f.read().strip().splitlines()\n","    class_ids = {int(line.split()[0]) for line in lines if len(line.split()) == 5}\n","    if class_ids == {0}:\n","        grouped['only_shadow'].append(base)\n","    elif class_ids == {1}:\n","        grouped['only_object'].append(base)\n","    elif class_ids == {0, 1}:\n","        grouped['both'].append(base)\n","\n","def stratified_split(data, train_ratio=0.8, val_ratio=0.1):\n","    random.shuffle(data)\n","    n = len(data)\n","    return (\n","        data[:int(n * train_ratio)],\n","        data[int(n * train_ratio):int(n * (train_ratio + val_ratio))],\n","        data[int(n * (train_ratio + val_ratio)):]\n","    )\n","\n","train, val, test = [], [], []\n","\n","for group in grouped.values():\n","    t, v, s = stratified_split(group)\n","    train += t\n","    val += v\n","    test += s\n","\n","# =============================================================\n","# STEP 7: Save Pascal VOC split files\n","# =============================================================\n","def save_split(list_, name):\n","    path = IMAGESETS_MAIN / f\"{name}.txt\"\n","    with open(path, \"w\") as f:\n","        for item in list_:\n","            f.write(item + \"\\n\")\n","\n","save_split(train, \"train\")\n","save_split(val, \"val\")\n","save_split(test, \"test\")\n","\n","# =============================================================\n","# STEP 8: Print final conversion summary\n","# =============================================================\n","print(\"========== CONVERSION COMPLETE ==========\")\n","print(f\"Total .txt files         : {len(txt_files)}\")\n","print(f\"Annotations converted    : {len(converted)}\")\n","print(f\"Skipped (no image)       : {skipped_no_image}\")\n","print(f\"Skipped (empty label)    : {skipped_empty}\")\n","print(f\"Skipped (bad class ID)   : {skipped_invalid_class}\")\n","print(f\"VOC Output Folder        : {TARGET_ROOT}\")\n","print(f\"ImageSets/Main/:         train.txt | val.txt | test.txt\")\n","\n","from collections import Counter\n","summary = {k: len(v) for k, v in grouped.items()}\n","print(f\"\\nClass Distribution: {summary}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DnlxxY6XaEV4","executionInfo":{"status":"ok","timestamp":1752977205873,"user_tz":240,"elapsed":352536,"user":{"displayName":"Gomis Kablan Assebian","userId":"09893333062250164075"}},"outputId":"53c8658c-f219-407b-97c4-d9b35f0f2be2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["Converting YOLO to VOC: 100%|██████████| 3464/3464 [05:19<00:00, 10.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["========== CONVERSION COMPLETE ==========\n","Total .txt files         : 3464\n","Annotations converted    : 1788\n","Skipped (no image)       : 0\n","Skipped (empty label)    : 1676\n","Skipped (bad class ID)   : 0\n","VOC Output Folder        : /content/drive/MyDrive/sonar-object-detection/data/line2voc\n","ImageSets/Main/:         train.txt | val.txt | test.txt\n","\n","Class Distribution: {'both': 1737, 'only_object': 33, 'only_shadow': 18}\n"]}]}]}