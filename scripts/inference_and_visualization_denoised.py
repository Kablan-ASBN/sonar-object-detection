# -*- coding: utf-8 -*-
"""inference_and_visualization_denoised.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gc5XA-gpZUqGaTut04rYLs4LqvHxOAPF
"""

# run batch inference using my denoised model and save results

import os
import cv2
import torch
import pandas as pd
import numpy as np
from PIL import Image
from pathlib import Path
from torchvision.transforms import ToTensor
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from voc_dataset import VOCDataset

# set base project path (mounted from Drive)
PROJECT_ROOT = Path("/content/drive/MyDrive/sonar-object-detection")

# use the preprocessed image folder
IMG_DIR = PROJECT_ROOT / "data" / "line2voc_preprocessed" / "JPEGImages"

# save outputs here
OUTPUT_DIR = PROJECT_ROOT / "outputs" / "vis_denoised"
PRED_CSV = PROJECT_ROOT / "outputs" / "preds_denoised.csv"

# load the trained model
MODEL_PATH = PROJECT_ROOT / "checkpoints" / "denoised_fasterrcnn.pth"

# create output folders if missing
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
PRED_CSV.parent.mkdir(parents=True, exist_ok=True)

# use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# load model structure and my trained weights
model = fasterrcnn_resnet50_fpn(weights=None)
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 3)
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.to(device)
model.eval()

# hold all predictions here
all_preds = []

# loop through all images in validation set
for img_path in IMG_DIR.glob("*.jpg"):
    image_pil = Image.open(img_path).convert("RGB")
    image_tensor = ToTensor()(image_pil).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(image_tensor)[0]

    boxes = output["boxes"].cpu()
    scores = output["scores"].cpu()
    labels = output["labels"].cpu()

    # convert image to OpenCV format for drawing
    img_np = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)

    for i in range(len(boxes)):
        score = scores[i].item()
        if score < 0.5:
            continue  # skip low confidence boxes

        x1, y1, x2, y2 = boxes[i].int().tolist()
        class_id = labels[i].item()

        # store prediction
        all_preds.append({
            "filename": img_path.name,
            "class_id": class_id,
            "score": score,
            "xmin": x1,
            "ymin": y1,
            "xmax": x2,
            "ymax": y2,
        })

        # draw box + score on image
        cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img_np, f"{score:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

    # save visual output
    out_path = OUTPUT_DIR / img_path.name
    cv2.imwrite(str(out_path), img_np)

# save prediction results to CSV
df = pd.DataFrame(all_preds)
df.to_csv(PRED_CSV, index=False)

print(f"Inference complete. Visuals saved to: {OUTPUT_DIR}")
print(f"Predictions saved to: {PRED_CSV}")