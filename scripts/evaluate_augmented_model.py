# -*- coding: utf-8 -*-
"""evaluate_augmented_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GpIcTNstc5aOS4ctjL__XvMHq8dmsbhf
"""

# evaluate Faster R-CNN model trained on CLAHE + augmented sonar images

import torch
from torch.utils.data import DataLoader
from torchvision import transforms as T
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchmetrics.detection.mean_ap import MeanAveragePrecision

# import my dataset class
import sys
sys.path.append('/content/drive/MyDrive/sonar-object-detection/scripts')
from voc_dataset import VOCDataset

# load the trained model
model = fasterrcnn_resnet50_fpn(weights="DEFAULT")
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 3)

# load model weights
checkpoint_path = "/content/drive/MyDrive/sonar-object-detection/checkpoints/augmented_fasterrcnn.pth"
model.load_state_dict(torch.load(checkpoint_path, map_location="cuda" if torch.cuda.is_available() else "cpu"))

# set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# setup validation data (same split used before)
DATASET_DIR = "/content/drive/MyDrive/sonar-object-detection/data/line2voc_preprocessed_augmented"
transform = T.ToTensor()
val_dataset = VOCDataset(DATASET_DIR, image_set="val", transforms=transform)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))

# init metric tracker
metric = MeanAveragePrecision()

# run evaluation
with torch.no_grad():
    for imgs, targets in val_loader:
        imgs = [img.to(device) for img in imgs]
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        outputs = model(imgs)

        preds = [{
            "boxes": o["boxes"].cpu(),
            "scores": o["scores"].cpu(),
            "labels": o["labels"].cpu()
        } for o in outputs]

        targs = [{
            "boxes": t["boxes"].cpu(),
            "labels": t["labels"].cpu()
        } for t in targets]

        metric.update(preds, targs)

# print the results
results = metric.compute()
print("Evaluation Results (Augmented Model):")
for k, v in results.items():
    print(f"{k}: {v:.4f}")