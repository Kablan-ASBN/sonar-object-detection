# -*- coding: utf-8 -*-
"""visualize_predictions_denoised.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12r_xWwJ4dPekgqJz1d5TXhtzcPBov2gG
"""

# visualize predictions from the denoised model

from voc_dataset import VOCDataset
from torchvision.transforms import ToTensor
import torch
import cv2
import numpy as np
from matplotlib import pyplot as plt
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

# set paths
MODEL_PATH = "/content/drive/MyDrive/sonar-object-detection/checkpoints/denoised_fasterrcnn.pth"
DATASET_ROOT = "/content/drive/MyDrive/sonar-object-detection/data/line2voc_preprocessed"

# load model
model = fasterrcnn_resnet50_fpn(weights=None)
num_classes = 3
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.to(device)
model.eval()

# load validation set
dataset = VOCDataset(DATASET_ROOT, image_set="val", transforms=ToTensor())

# visualize a few predictions
for i in range(5):
    img, _ = dataset[i]
    img_tensor = img.unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(img_tensor)[0]

    img_np = img.mul(255).byte().permute(1, 2, 0).cpu().numpy()
    img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR).copy()

    for box, score in zip(output["boxes"], output["scores"]):
        if score < 0.5:
            continue
        x1, y1, x2, y2 = box.int().tolist()
        cv2.rectangle(img_np, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img_np, f"{score:.2f}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

    plt.imshow(cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.show()